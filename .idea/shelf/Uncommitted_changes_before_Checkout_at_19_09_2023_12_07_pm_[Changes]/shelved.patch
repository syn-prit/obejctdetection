Index: app/src/main/java/com/tensorflow/objectscanner/fragments/CameraFragment.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>package com.tensorflow.objectscanner.fragments;\r\n\r\nimport static androidx.camera.core.ImageAnalysis.OUTPUT_IMAGE_FORMAT_RGBA_8888;\r\n\r\nimport android.annotation.SuppressLint;\r\nimport android.content.res.Configuration;\r\nimport android.graphics.Bitmap;\r\nimport android.media.Image;\r\nimport android.os.Bundle;\r\nimport android.util.Log;\r\nimport android.view.LayoutInflater;\r\nimport android.view.View;\r\nimport android.view.ViewGroup;\r\nimport android.widget.AdapterView;\r\nimport android.widget.Toast;\r\n\r\nimport androidx.annotation.NonNull;\r\nimport androidx.annotation.Nullable;\r\nimport androidx.camera.core.AspectRatio;\r\nimport androidx.camera.core.Camera;\r\nimport androidx.camera.core.CameraSelector;\r\nimport androidx.camera.core.ImageAnalysis;\r\nimport androidx.camera.core.ImageProxy;\r\nimport androidx.camera.core.Preview;\r\nimport androidx.camera.lifecycle.ProcessCameraProvider;\r\nimport androidx.core.content.ContextCompat;\r\nimport androidx.fragment.app.Fragment;\r\nimport androidx.lifecycle.Lifecycle;\r\nimport androidx.lifecycle.LifecycleObserver;\r\nimport androidx.lifecycle.OnLifecycleEvent;\r\nimport androidx.navigation.NavController;\r\nimport androidx.navigation.Navigation;\r\n\r\nimport com.google.common.util.concurrent.ListenableFuture;\r\nimport com.tensorflow.objectscanner.R;\r\nimport com.tensorflow.objectscanner.databinding.FragmentCameraBinding;\r\nimport com.tensorflow.objectscanner.helperclasses.ObjectDetectorHelper;\r\n\r\nimport org.tensorflow.lite.task.gms.vision.detector.Detection;\r\n\r\nimport java.nio.ByteBuffer;\r\nimport java.util.LinkedList;\r\nimport java.util.List;\r\nimport java.util.concurrent.ExecutionException;\r\nimport java.util.concurrent.ExecutorService;\r\nimport java.util.concurrent.Executors;\r\n\r\n\r\npublic class CameraFragment extends Fragment implements ObjectDetectorHelper.DetectorListener {\r\n\r\n\r\n    private static final String TAG = \"CameraFragment\";\r\n\r\n    public static FragmentCameraBinding fragmentCameraBinding;\r\n\r\n    public static FragmentCameraBinding fragmentCameraBinding() {\r\n        return fragmentCameraBinding;\r\n    }\r\n\r\n    public ObjectDetectorHelper objectDetectorHelper;\r\n    public static Bitmap bitmapBuffer = null;\r\n    public static Preview preview = null;\r\n    public static ImageAnalysis imageAnalyzer = null;\r\n    public static Camera camera = null;\r\n    public static  ProcessCameraProvider cameraProvider;\r\n    //Blocking camera operations are performed using this executor\r\n    public static ExecutorService cameraExecutor;\r\n\r\n    @Override\r\n    public void onResume() {\r\n        super.onResume();\r\n        if (!PermissionsFragment.hasPermissions(requireContext())) {\r\n            getLifecycle().addObserver(new LifecycleObserver() {\r\n                @OnLifecycleEvent(Lifecycle.Event.ON_RESUME)\r\n                public void onStartEvent() {\r\n                    NavController navController;\r\n                    navController = Navigation.findNavController(requireActivity(), R.id.fragment_container);\r\n                    navController.navigate(R.id.action_camera_to_permissions);\r\n                }\r\n            });\r\n        }\r\n    }\r\n\r\n    @Override\r\n    public void onDestroyView() {\r\n        super.onDestroyView();\r\n        fragmentCameraBinding = null;\r\n        // Shut down our background executor\r\n        cameraExecutor.shutdown();\r\n    }\r\n\r\n\r\n    @Override\r\n    public View onCreateView(LayoutInflater inflater, ViewGroup container,\r\n                             Bundle savedInstanceState) {\r\n        // Inflate the layout for this fragment\r\n        fragmentCameraBinding = FragmentCameraBinding.inflate(inflater, container, false);\r\n        return fragmentCameraBinding.getRoot();\r\n\r\n    }\r\n\r\n    @Override\r\n    public void onViewCreated(View view, @Nullable Bundle savedInstanceState) {\r\n        super.onViewCreated(view, savedInstanceState);\r\n        //objectDetectorHelper = new ObjectDetectorHelper(getContext(), getActivity());\r\n//        objectDetectorHelper = new ObjectDetectorHelper();\r\n\r\n        objectDetectorHelper = new ObjectDetectorHelper( requireContext(), this);\r\n\r\n\r\n        // Attach listeners to UI control widgets\r\n        initBottomSheetControls();\r\n\r\n    }\r\n\r\n    private void initBottomSheetControls() {\r\n        // When clicked, lower detection score threshold floor\r\n        fragmentCameraBinding.bottomSheetLayout.thresholdMinus.setOnClickListener(v -> {\r\n            if (objectDetectorHelper.getThreshold() >= 0.1) {\r\n                float i = objectDetectorHelper.getThreshold();\r\n                i -= 0.1f;\r\n                objectDetectorHelper.setThreshold(i);\r\n                updateControlsUi();\r\n            }\r\n        });\r\n\r\n        // When clicked, raise detection score threshold floor\r\n        fragmentCameraBinding.bottomSheetLayout.thresholdPlus.setOnClickListener(v -> {\r\n            if (objectDetectorHelper.getThreshold() <= 0.8) {\r\n                float i = objectDetectorHelper.getThreshold();\r\n                i += 0.1f;\r\n                objectDetectorHelper.setThreshold(i);\r\n                updateControlsUi();\r\n            }\r\n        });\r\n\r\n        // When clicked, reduce the number of objects that can be detected at a time\r\n        fragmentCameraBinding.bottomSheetLayout.maxResultsMinus.setOnClickListener(v -> {\r\n            if (objectDetectorHelper.getMaxResults() > 1) {\r\n                int i = objectDetectorHelper.getMaxResults();\r\n                i--;\r\n                objectDetectorHelper.setMaxResults(i);\r\n                updateControlsUi();\r\n            }\r\n        });\r\n\r\n        // When clicked, increase the number of objects that can be detected at a time\r\n        fragmentCameraBinding.bottomSheetLayout.maxResultsPlus.setOnClickListener(v -> {\r\n            if (objectDetectorHelper.getMaxResults() < 5) {\r\n                int i = objectDetectorHelper.getMaxResults();\r\n                i++;\r\n                objectDetectorHelper.setMaxResults(i);\r\n                updateControlsUi();\r\n            }\r\n        });\r\n\r\n        // When clicked, decrease the number of threads used for detection\r\n        fragmentCameraBinding.bottomSheetLayout.threadsMinus.setOnClickListener(v -> {\r\n            if (objectDetectorHelper.getNumThreads() > 1) {\r\n                int i = objectDetectorHelper.getNumThreads();\r\n                i--;\r\n                objectDetectorHelper.setNumThreads(i);\r\n                updateControlsUi();\r\n            }\r\n        });\r\n\r\n        // When clicked, increase the number of threads used for detection\r\n        fragmentCameraBinding.bottomSheetLayout.threadsPlus.setOnClickListener(v -> {\r\n            if (objectDetectorHelper.getNumThreads() < 4) {\r\n                int i = objectDetectorHelper.getNumThreads();\r\n                i++;\r\n                objectDetectorHelper.setNumThreads(i);\r\n                updateControlsUi();\r\n            }\r\n        });\r\n\r\n        // When clicked, change the underlying hardware used for inference (CPU, GPU, NNAPI)\r\n        fragmentCameraBinding.bottomSheetLayout.spinnerDelegate.setSelection(0, false);\r\n        fragmentCameraBinding.bottomSheetLayout.spinnerDelegate.setOnItemSelectedListener(new AdapterView.OnItemSelectedListener() {\r\n            @Override\r\n            public void onItemSelected(AdapterView<?> parentView, View selectedItemView, int position, long id) {\r\n                objectDetectorHelper.setCurrentDelegate(position);\r\n                updateControlsUi();\r\n            }\r\n\r\n            @Override\r\n            public void onNothingSelected(AdapterView<?> parentView) {\r\n                // No action\r\n            }\r\n        });\r\n\r\n        // When clicked, change the underlying model used for object detection\r\n        // GPU, and NNAPI\r\n        fragmentCameraBinding.bottomSheetLayout.spinnerModel.setSelection(0, false);\r\n        fragmentCameraBinding.bottomSheetLayout.spinnerModel.setOnItemSelectedListener(new AdapterView.OnItemSelectedListener() {\r\n            @Override\r\n            public void onItemSelected(AdapterView<?> parentView, View selectedItemView, int position, long id) {\r\n                objectDetectorHelper.setCurrentModel(position);\r\n                updateControlsUi();\r\n            }\r\n\r\n            @Override\r\n            public void onNothingSelected(AdapterView<?> parentView) {\r\n                // No action\r\n            }\r\n        });\r\n    }\r\n\r\n\r\n    @SuppressLint({\"SetTextI18n\", \"DefaultLocale\"})\r\n    private void updateControlsUi() {\r\n        fragmentCameraBinding.bottomSheetLayout.maxResultsValue.setText(Integer.toString(objectDetectorHelper.getMaxResults()));\r\n        fragmentCameraBinding.bottomSheetLayout.thresholdValue.setText(String.format(\"%.2f\", objectDetectorHelper.getThreshold()));\r\n        fragmentCameraBinding.bottomSheetLayout.threadsValue.setText(Integer.toString(objectDetectorHelper.getNumThreads()));\r\n\r\n        // Needs to be cleared instead of reinitialized because the GPU\r\n        // delegate needs to be initialized on the thread using it when applicable\r\n        objectDetectorHelper.clearObjectDetector();\r\n        fragmentCameraBinding.overlay.clear();\r\n    }\r\n\r\n    private void setUpCamera() {\r\n        Log.e(\"CameraFragment\",\"setUpCamera\");\r\n        //  final ProcessCameraProvider[] cameraProvider = new ProcessCameraProvider[100];\r\n        ListenableFuture<ProcessCameraProvider> cameraProviderFuture = ProcessCameraProvider.getInstance(requireContext());\r\n        cameraProviderFuture.addListener(new Runnable() {\r\n            @Override\r\n            public void run() {\r\n                try {\r\n                    // CameraProvider\r\n                    cameraProvider = cameraProviderFuture.get();\r\n\r\n                    // Build and bind the camera use cases\r\n                    bindCameraUseCases();\r\n                } catch (ExecutionException | InterruptedException e) {\r\n                    // Handle exceptions if necessary\r\n                }\r\n            }\r\n        }, ContextCompat.getMainExecutor(requireContext()));\r\n\r\n    }\r\n\r\n    public void bindCameraUseCases() {\r\n        if (cameraProvider == null) {\r\n            throw new IllegalStateException(\"Camera initialization failed.\");\r\n        }\r\n\r\n        // CameraSelector - assumes we're only using the back camera\r\n        CameraSelector cameraSelector = new CameraSelector.Builder()\r\n                .requireLensFacing(CameraSelector.LENS_FACING_BACK)\r\n                .build();\r\n        // Only using the 4:3 ratio because this is the closest to our models\r\n        preview = new Preview.Builder()\r\n                .setTargetAspectRatio(AspectRatio.RATIO_4_3)\r\n                .setTargetRotation(fragmentCameraBinding.viewFinder.getDisplay().getRotation())\r\n                .build();\r\n\r\n        // ImageAnalysis configuration\r\n        imageAnalyzer = new ImageAnalysis.Builder()\r\n                .setTargetAspectRatio(AspectRatio.RATIO_4_3)\r\n                .setTargetRotation(fragmentCameraBinding.viewFinder.getDisplay().getRotation())\r\n                .setBackpressureStrategy(ImageAnalysis.STRATEGY_KEEP_ONLY_LATEST)\r\n                .setOutputImageFormat(OUTPUT_IMAGE_FORMAT_RGBA_8888)\r\n                .build();\r\n\r\n        imageAnalyzer.setAnalyzer(cameraExecutor, image -> {\r\n\r\n            boolean bitmapBufferInitialized = true;\r\n            if (!bitmapBufferInitialized) {\r\n                // The image rotation and RGB image buffer are initialized only once\r\n                // the analyzer has started running\r\n                bitmapBuffer = Bitmap.createBitmap(\r\n                        image.getWidth(),\r\n                        image.getHeight(),\r\n                        Bitmap.Config.ARGB_8888\r\n                );\r\n                detectObjects(image);\r\n            }\r\n        });\r\n\r\n        cameraProvider.unbindAll();\r\n\r\n        try {\r\n            // A variable number of use-cases can be passed here -\r\n            // camera provides access to CameraControl & CameraInfo\r\n            camera = cameraProvider.bindToLifecycle(this, cameraSelector, preview, imageAnalyzer);\r\n\r\n            // Attach the viewfinder's surface provider to the preview use case\r\n            if (preview != null) {\r\n                preview.setSurfaceProvider(fragmentCameraBinding.viewFinder.getSurfaceProvider());\r\n            }\r\n        } catch (Exception exc) {\r\n            Log.e(TAG, \"Use case binding failed\", exc);\r\n        }\r\n    }\r\n\r\n    public static void detectObjects(ImageProxy image) {\r\n        // Copy RGB bits to the shared bitmap buffer\r\n        Log.e(\"CameraFragment\",\"detectObjects\");\r\n            Image.Plane[] planes = (Image.Plane[]) image.getPlanes();\r\n            ByteBuffer buffer = planes[0].getBuffer();\r\n            bitmapBuffer.copyPixelsFromBuffer(buffer);\r\n\r\n        int imageRotation = image.getImageInfo().getRotationDegrees();\r\n        ObjectDetectorHelper.detect(bitmapBuffer, imageRotation);\r\n\r\n\r\n    }\r\n\r\n\r\n//        ByteBuffer planeBuffer = image.getPlanes()[0].getBuffer();\r\n//        bitmapBuffer.copyPixelsFromBuffer(planeBuffer);\r\n//\r\n//        int imageRotation = image.getImageInfo().getRotationDegrees();\r\n//\r\n//        // Pass Bitmap and rotation to the object detector helper for processing and detection\r\n//        objectDetectorHelper.detect(bitmapBuffer, imageRotation);\r\n\r\n\r\n\r\n\r\n\r\n\r\n    @Override\r\n    public void onConfigurationChanged(@NonNull Configuration newConfig) {\r\n        super.onConfigurationChanged(newConfig);\r\n        if (imageAnalyzer != null) {\r\n            imageAnalyzer.setTargetRotation(fragmentCameraBinding.viewFinder.getDisplay().getRotation());\r\n        }\r\n    }\r\n\r\n\r\n    @Override\r\n    public void onInitialized() {\r\n        Log.e(\"CameraFragment\",\"onInitialized\");\r\n        objectDetectorHelper.setupObjectDetector();\r\n// Initialize our background executor\r\n        cameraExecutor = Executors.newSingleThreadExecutor();\r\n\r\n// Wait for the views to be properly laid out\r\n        // Set up the camera and its use cases\r\n        fragmentCameraBinding.viewFinder.post(this::setUpCamera);\r\n        fragmentCameraBinding.progressCircular.setVisibility(View.GONE);\r\n\r\n\r\n    }\r\n\r\n    @Override\r\n    public void onError(String error) {\r\n        if (getActivity() != null) {\r\n            getActivity().runOnUiThread(() -> Toast.makeText(requireContext(), error, Toast.LENGTH_SHORT).show());\r\n        }\r\n\r\n    }\r\n\r\n    @Override\r\n    public void onResults(List<Detection> results, long inferenceTime, int imageHeight, int imageWidth) {\r\n        Log.e(\"CameraFragment\",\"onResults---------------->1\");\r\n\r\n        if (getActivity() != null) {\r\n            getActivity().runOnUiThread(() -> {\r\n\r\n                Log.e(\"CameraFragment\",\"onResults\");\r\n\r\n                fragmentCameraBinding.bottomSheetLayout.inferenceTimeVal.setText(\r\n                        String.format(\"%d ms\", inferenceTime)\r\n                );\r\n\r\n                // Pass necessary information to OverlayView for drawing on the canvas\r\n                fragmentCameraBinding.overlay.setResults(\r\n                        (results != null) ? results : new LinkedList<>(),\r\n                        imageHeight,\r\n                        imageWidth\r\n                );\r\n\r\n                // Force a redraw\r\n                fragmentCameraBinding.overlay.invalidate();\r\n\r\n            });\r\n        }\r\n\r\n    }\r\n}
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/app/src/main/java/com/tensorflow/objectscanner/fragments/CameraFragment.java b/app/src/main/java/com/tensorflow/objectscanner/fragments/CameraFragment.java
--- a/app/src/main/java/com/tensorflow/objectscanner/fragments/CameraFragment.java	
+++ b/app/src/main/java/com/tensorflow/objectscanner/fragments/CameraFragment.java	
@@ -69,6 +69,7 @@
     @Override
     public void onResume() {
         super.onResume();
+        Log.e("CameraFragment","CameraFragment---->onResume");
         if (!PermissionsFragment.hasPermissions(requireContext())) {
             getLifecycle().addObserver(new LifecycleObserver() {
                 @OnLifecycleEvent(Lifecycle.Event.ON_RESUME)
@@ -84,6 +85,7 @@
     @Override
     public void onDestroyView() {
         super.onDestroyView();
+        Log.e("CameraFragment","CameraFragment---->onDestroyView");
         fragmentCameraBinding = null;
         // Shut down our background executor
         cameraExecutor.shutdown();
@@ -94,6 +96,7 @@
     public View onCreateView(LayoutInflater inflater, ViewGroup container,
                              Bundle savedInstanceState) {
         // Inflate the layout for this fragment
+        Log.e("CameraFragment","CameraFragment---->onCreateView");
         fragmentCameraBinding = FragmentCameraBinding.inflate(inflater, container, false);
         return fragmentCameraBinding.getRoot();
 
@@ -105,6 +108,7 @@
         //objectDetectorHelper = new ObjectDetectorHelper(getContext(), getActivity());
 //        objectDetectorHelper = new ObjectDetectorHelper();
 
+        Log.e("CameraFragment","CameraFragment---->onViewCreated");
         objectDetectorHelper = new ObjectDetectorHelper( requireContext(), this);
 
 
@@ -209,6 +213,7 @@
 
     @SuppressLint({"SetTextI18n", "DefaultLocale"})
     private void updateControlsUi() {
+
         fragmentCameraBinding.bottomSheetLayout.maxResultsValue.setText(Integer.toString(objectDetectorHelper.getMaxResults()));
         fragmentCameraBinding.bottomSheetLayout.thresholdValue.setText(String.format("%.2f", objectDetectorHelper.getThreshold()));
         fragmentCameraBinding.bottomSheetLayout.threadsValue.setText(Integer.toString(objectDetectorHelper.getNumThreads()));
@@ -220,7 +225,7 @@
     }
 
     private void setUpCamera() {
-        Log.e("CameraFragment","setUpCamera");
+        Log.e("CameraFragment","CameraFragment---->setUpCamera");
         //  final ProcessCameraProvider[] cameraProvider = new ProcessCameraProvider[100];
         ListenableFuture<ProcessCameraProvider> cameraProviderFuture = ProcessCameraProvider.getInstance(requireContext());
         cameraProviderFuture.addListener(new Runnable() {
@@ -296,7 +301,7 @@
 
     public static void detectObjects(ImageProxy image) {
         // Copy RGB bits to the shared bitmap buffer
-        Log.e("CameraFragment","detectObjects");
+        Log.e("CameraFragment","CameraFragment---->detectObjects");
             Image.Plane[] planes = (Image.Plane[]) image.getPlanes();
             ByteBuffer buffer = planes[0].getBuffer();
             bitmapBuffer.copyPixelsFromBuffer(buffer);
@@ -332,7 +337,8 @@
 
     @Override
     public void onInitialized() {
-        Log.e("CameraFragment","onInitialized");
+        Log.e("CameraFragment","CameraFragment---->onInitialized");
+
         objectDetectorHelper.setupObjectDetector();
 // Initialize our background executor
         cameraExecutor = Executors.newSingleThreadExecutor();
@@ -355,12 +361,12 @@
 
     @Override
     public void onResults(List<Detection> results, long inferenceTime, int imageHeight, int imageWidth) {
-        Log.e("CameraFragment","onResults---------------->1");
+        Log.e("CameraFragment","CameraFragment---->onResults11111");
 
         if (getActivity() != null) {
             getActivity().runOnUiThread(() -> {
 
-                Log.e("CameraFragment","onResults");
+                Log.e("CameraFragment","CameraFragment---->onResults222222");
 
                 fragmentCameraBinding.bottomSheetLayout.inferenceTimeVal.setText(
                         String.format("%d ms", inferenceTime)
Index: app/src/main/java/com/tensorflow/objectscanner/helperclasses/ObjectDetectorHelper.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>package com.tensorflow.objectscanner.helperclasses;\r\n\r\nimport android.content.Context;\r\nimport android.graphics.Bitmap;\r\nimport android.os.SystemClock;\r\nimport android.util.Log;\r\n\r\nimport androidx.annotation.NonNull;\r\n\r\nimport com.google.android.gms.tasks.OnFailureListener;\r\nimport com.google.android.gms.tasks.OnSuccessListener;\r\nimport com.google.android.gms.tasks.SuccessContinuation;\r\nimport com.google.android.gms.tasks.Task;\r\nimport com.google.android.gms.tflite.client.TfLiteInitializationOptions;\r\nimport com.google.android.gms.tflite.gpu.support.TfLiteGpu;\r\nimport com.tensorflow.objectscanner.fragments.CameraFragment;\r\n\r\nimport org.tensorflow.lite.support.image.ImageProcessor;\r\nimport org.tensorflow.lite.support.image.TensorImage;\r\nimport org.tensorflow.lite.support.image.ops.Rot90Op;\r\nimport org.tensorflow.lite.task.core.BaseOptions;\r\nimport org.tensorflow.lite.task.gms.vision.TfLiteVision;\r\nimport org.tensorflow.lite.task.gms.vision.detector.Detection;\r\nimport org.tensorflow.lite.task.gms.vision.detector.ObjectDetector;\r\n\r\nimport java.util.List;\r\n\r\npublic class ObjectDetectorHelper {\r\n\r\n    public static float threshold = 0.5f;\r\n    public static int numThreads = 2;\r\n    public static int maxResults = 3;\r\n    public static int currentDelegate = 0;\r\n    public static int currentModel = 0;\r\n    public static Context context;\r\n    public static DetectorListener objectDetectorListener;\r\n\r\n    public final String TAG = \"ObjectDetectionHelper\";\r\n    public static boolean gpuSupported = false;\r\n    public static ObjectDetector objectDetector = null; // For this example, this needs to be a var so it can be reset on changes. If the ObjectDetector will not change, a lazy val would be preferable.\r\n    public final String TAGs = \"TfLiteVision\";\r\n\r\n    public static final int DELEGATE_CPU = 0;\r\n    public static final int DELEGATE_GPU = 1;\r\n    public static final int DELEGATE_NNAPI = 2;\r\n    public static final int MODEL_MOBILENETV1 = 0;\r\n    public static final int MODEL_EFFICIENTDETV0 = 1;\r\n    public static final int MODEL_EFFICIENTDETV1 = 2;\r\n    public static final int MODEL_EFFICIENTDETV2 = 3;\r\n\r\n    public ObjectDetectorHelper(Context requireContext, CameraFragment cameraFragment) {\r\n        context = requireContext;\r\n        objectDetectorListener = cameraFragment;\r\n        test();\r\n        //new ObjectDetectorHelper();\r\n\r\n\r\n    }\r\n\r\n    public static void setThreshold(float threshold) {\r\n        ObjectDetectorHelper.threshold = threshold;\r\n    }\r\n\r\n\r\n    public static float getThreshold() {\r\n        return threshold;\r\n    }\r\n\r\n\r\n    public static int getNumThreads() {\r\n        return numThreads;\r\n    }\r\n\r\n\r\n    public static int getMaxResults() {\r\n        return maxResults;\r\n    }\r\n\r\n    public static void setNumThreads(int numThreads) {\r\n        ObjectDetectorHelper.numThreads = numThreads;\r\n    }\r\n\r\n    public static void setMaxResults(int maxResults) {\r\n        ObjectDetectorHelper.maxResults = maxResults;\r\n    }\r\n\r\n    public static void setupObjectDetector() {\r\n        if (!TfLiteVision.isInitialized()) {\r\n            Log.e(\"TfLiteVision\", \"setupObjectDetector: TfLiteVision is not initialized yet\");\r\n        }\r\n        ObjectDetector.ObjectDetectorOptions.Builder optionsBuilder =\r\n                ObjectDetector.ObjectDetectorOptions.builder().\r\n                        setScoreThreshold(threshold).\r\n                        setMaxResults(maxResults);\r\n        BaseOptions.Builder baseOptionsBuilder = BaseOptions.builder().setNumThreads(numThreads);\r\n\r\n\r\n        switch (currentDelegate) {\r\n            case DELEGATE_CPU:\r\n                // Default\r\n                break;\r\n            case DELEGATE_GPU:\r\n                if (gpuSupported) {\r\n                    baseOptionsBuilder.useGpu();\r\n                } else {\r\n                    objectDetectorListener.onError(\"GPU is not supported on this device\");\r\n                }\r\n                break;\r\n            case DELEGATE_NNAPI:\r\n                baseOptionsBuilder.useNnapi();\r\n                break;\r\n        }\r\n\r\n        optionsBuilder.setBaseOptions(baseOptionsBuilder.build());\r\n\r\n\r\n        String modelName;\r\n        switch (currentModel) {\r\n            case MODEL_MOBILENETV1:\r\n                modelName = \"mobilenetv1.tflite\";\r\n                break;\r\n            case MODEL_EFFICIENTDETV0:\r\n                modelName = \"efficientdet-lite0.tflite\";\r\n                break;\r\n            case MODEL_EFFICIENTDETV1:\r\n                modelName = \"efficientdet-lite1.tflite\";\r\n                break;\r\n            case MODEL_EFFICIENTDETV2:\r\n                modelName = \"efficientdet-lite2.tflite\";\r\n                break;\r\n            default:\r\n                modelName = \"mobilenetv1.tflite\";\r\n                break;\r\n        }\r\n        try {\r\n            objectDetector = ObjectDetector.createFromFileAndOptions(context, modelName, optionsBuilder.build());\r\n        } catch (Exception e) {\r\n            objectDetectorListener.onError(\"Object detector failed to initialize. See error logs for details\");\r\n            Log.e(\"TAG\", \"TFLite failed to load model with error: \" + e.getMessage());\r\n        }\r\n\r\n    }\r\n\r\n\r\n    public static void setCurrentDelegate(int currentDelegate) {\r\n        ObjectDetectorHelper.currentDelegate = currentDelegate;\r\n    }\r\n\r\n\r\n    public static void setCurrentModel(int currentModel) {\r\n        ObjectDetectorHelper.currentModel = currentModel;\r\n    }\r\n\r\n    public static Context getContext() {\r\n        return context;\r\n    }\r\n\r\n\r\n    public static void clearObjectDetector() {\r\n        objectDetector = null;\r\n    }\r\n\r\n    public static void detect(Bitmap image, int imageRotation) {\r\n        Log.e(\"TfLiteVision\", \"setupObjectDetector: TfLiteVision is not initialized yet\");\r\n//        Log.e(TAG, \"detect: TfLiteVision is not initialized yet\");\r\n        if (!TfLiteVision.isInitialized()) {\r\n            Log.e(\"TfLiteVision\", \"detect: TfLiteVision is not initialized yet\");\r\n            return;\r\n        }\r\n        if (objectDetector == null) {\r\n            setupObjectDetector();\r\n        }\r\n\r\n        // Inference time is the difference between the system time at the start and finish of the\r\n        // process\r\n        long inferenceTime = SystemClock.uptimeMillis();\r\n\r\n        // Create preprocessor for the image.\r\n        // See https://www.tensorflow.org/lite/inference_with_metadata/\r\n        //            lite_support#imageprocessor_architecture\r\n\r\n        ImageProcessor imageProcessor = new ImageProcessor.Builder()\r\n                .add(new Rot90Op(-imageRotation / 90))\r\n                .build();\r\n\r\n        // Preprocess the image and convert it into a TensorImage for detection.\r\n        TensorImage tensorImage = imageProcessor.process(TensorImage.fromBitmap(image));\r\n\r\n        //results\r\n        List<Detection> results = objectDetector.detect(tensorImage);\r\n        inferenceTime = SystemClock.uptimeMillis() - inferenceTime;\r\n        objectDetectorListener.onResults(\r\n                results,\r\n                inferenceTime,\r\n                tensorImage.getHeight(),\r\n                tensorImage.getWidth()\r\n        );\r\n    }\r\n\r\n    private void test() {\r\n        Log.e(TAGs, \"TfLiteVisionTfLiteVisionTfLiteVisionTfLiteVisionTfLiteVisionTfLiteVision\");\r\n        TfLiteGpu.isGpuDelegateAvailable(getContext()).onSuccessTask(new SuccessContinuation<Boolean, Void>() {\r\n                    @NonNull\r\n                    @Override\r\n                    public Task<Void> then(Boolean gpuAvailable) throws Exception {\r\n                        TfLiteInitializationOptions.Builder optionsBuilder =\r\n                                TfLiteInitializationOptions.builder();\r\n                        if (gpuAvailable != null && gpuAvailable) {\r\n                            optionsBuilder.setEnableGpuDelegateSupport(true);\r\n                        }\r\n                        return TfLiteVision.initialize(getContext(), optionsBuilder.build());\r\n                    }\r\n                }).addOnSuccessListener(new OnSuccessListener<Void>() {\r\n                    @Override\r\n                    public void onSuccess(Void aVoid) {\r\n                        objectDetectorListener.onInitialized();\r\n                    }\r\n                })\r\n                .addOnFailureListener(new OnFailureListener() {\r\n                    @Override\r\n                    public void onFailure(Exception e) {\r\n                        objectDetectorListener.onError(\"TfLiteVision failed to initialize: \" + e.getMessage());\r\n                    }\r\n                });\r\n    }\r\n\r\n    public interface DetectorListener {\r\n\r\n        void onInitialized();\r\n\r\n        void onError(String error);\r\n\r\n        void onResults(List<Detection> results, long inferenceTime, int imageHeight, int imageWidth);\r\n\r\n\r\n    }\r\n\r\n\r\n}
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/app/src/main/java/com/tensorflow/objectscanner/helperclasses/ObjectDetectorHelper.java b/app/src/main/java/com/tensorflow/objectscanner/helperclasses/ObjectDetectorHelper.java
--- a/app/src/main/java/com/tensorflow/objectscanner/helperclasses/ObjectDetectorHelper.java	
+++ b/app/src/main/java/com/tensorflow/objectscanner/helperclasses/ObjectDetectorHelper.java	
@@ -86,7 +86,8 @@
 
     public static void setupObjectDetector() {
         if (!TfLiteVision.isInitialized()) {
-            Log.e("TfLiteVision", "setupObjectDetector: TfLiteVision is not initialized yet");
+            Log.e("CameraFragment","ObjectDetectionHelper---->setupObjectDetector");
+            //Log.e("TfLiteVision", "setupObjectDetector: TfLiteVision is not initialized yet");
         }
         ObjectDetector.ObjectDetectorOptions.Builder optionsBuilder =
                 ObjectDetector.ObjectDetectorOptions.builder().
@@ -136,7 +137,7 @@
             objectDetector = ObjectDetector.createFromFileAndOptions(context, modelName, optionsBuilder.build());
         } catch (Exception e) {
             objectDetectorListener.onError("Object detector failed to initialize. See error logs for details");
-            Log.e("TAG", "TFLite failed to load model with error: " + e.getMessage());
+            Log.e("CameraFragment","ObjectDetectionHelper---->TFLite failed to load model with error: " + e.getMessage());
         }
 
     }
@@ -161,10 +162,12 @@
     }
 
     public static void detect(Bitmap image, int imageRotation) {
-        Log.e("TfLiteVision", "setupObjectDetector: TfLiteVision is not initialized yet");
+        Log.e("CameraFragment","ObjectDetectionHelper---->detect");
+
 //        Log.e(TAG, "detect: TfLiteVision is not initialized yet");
         if (!TfLiteVision.isInitialized()) {
-            Log.e("TfLiteVision", "detect: TfLiteVision is not initialized yet");
+
+            Log.e("CameraFragment","ObjectDetectionHelper---->detect: TfLiteVision is not initialized yet");
             return;
         }
         if (objectDetector == null) {
@@ -198,7 +201,7 @@
     }
 
     private void test() {
-        Log.e(TAGs, "TfLiteVisionTfLiteVisionTfLiteVisionTfLiteVisionTfLiteVisionTfLiteVision");
+        Log.e("CameraFragment","ObjectDetectionHelper---->init");
         TfLiteGpu.isGpuDelegateAvailable(getContext()).onSuccessTask(new SuccessContinuation<Boolean, Void>() {
                     @NonNull
                     @Override
